# -*- coding: utf-8 -*-
"""Proyek Akhir Recomender_System_dicoding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DxOgIBe56EGVX21S25_eSIDhD-xztg4s

# **Sistem Rekomendasi Movie - Submission Machine Learning Terapan**

Nama : Ali Mustofa

Asal : Jakarta Timur, Jakarta

## **Project Overview**
Sistem rekomendasi buku merupakan sistem yang merekomendasikan buku kepada pembaca atau pembeli. Sistem rekomendasi yang saya buat ini didasarkan dengan peferensi kesukaan pengguna dimasa lalu, serta rating dari buku tersebut. Sistem rekomendasi telah menjadi lazim dalam beberapa tahun terakhir, karena mereka menangani masalah informasi dengan menyarankan penggunaan produk yang paling relevan dari sejumlah data besar. Sekarang sistem rekomendasi sangat penting dibeberapa industri karena dapat menghasilkan pendapatan yang sangat besar jika efisien. Dalam makalah ini, diusulkan sistem rekomendasi buku berbasis model hibrida yang memanfaatkan pengelompokan K-means yang ditingkatkan ditambah dengan algoritma genetika (GAs) untuk mempartisi ruang pengguna yang ditransformasikan. Ini menggunakan teknik reduksi data analisis komponen utama (PCA) untuk memadat ruang populasi buku yang juga dapat mengurangi kompleksitas komputasi dalam rekomendasi buku cerdas. Hasil eksperimen pada dataset Arashnic menunjukkan bahwa pendekatan yang diusulkan dapat memberikan kinerja tinggi dalam hal akurasi, dan menghasilkan rekomendasi film yang lebih andal dan personal jika dibandingkan dengan metode yang ada.

## **Business Understanding**

### **Problem Statements**
1.   Bagaimana cara merecomendasikan buku yang disukai oleh pembaca lain, direcomendasikan ke pembaca lain.

### **Goals**
Dapat membuat sistem rekomendasi yang akurat berdasarkan ratings dan aktivitas pengguna pada masa lalu.

### **Solution approach**
Solusi yang saya buat yaitu dengan menggunakan 2 algoritma Machine Learning sistem rekomendasi,yaitu :


1.   Content Based Filtering adalah algoritma yang merekomendasikan item serupa dengan apa yang disukai pengguna, berdasarkan tindakan mereka sebelumnya atau umpan balik eksplisit.
2.   Collaborative Filtering. adalah algoritma yang bergantung pada pendapat komunitas pengguna. Dia tidak memerlukan atribut untuk setiap itemnya.


Algoritma Content Based Filtering digunakan untuk merekemondesikan buku berdasarkan aktivitas pengguna pada masa lalu, sedangkan algoritma Collabarative Filltering digunakan untuk merekomendasikan buku berdasarkan ratings yang paling tinggi.

## Data Understanding

Data atau dataset yang digunakan pada proyek machine learning ini adalah data **Book Recommendation Dataset** yang didapat dari situs kaggle. Link dataset dapat dilihat dari tautan berikut [book-recommendation-dataset](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset?select=Books.csv)
"""

!pip install -q kaggle

import json

kaggle_token = {"username":"alimustoofaa","key":"2813bea47db4baf7c78d2563796b9f12"}

with open('kaggle.json', "w") as outfile:
    json.dump(kaggle_token, outfile)

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

"""Download data dengan menggunakan perintah API Command dari library kaggle"""

!kaggle datasets download -d arashnic/book-recommendation-dataset
!unzip book-recommendation-dataset.zip

"""Membaca data-data tersebut menggunakan pandas library dengan fungsi read_csv"""

import pandas as pd
 
books = pd.read_csv('/content/Books.csv')
ratings = pd.read_csv('/content/Ratings.csv')
users = pd.read_csv('/content/Users.csv')

print('Jumlah data books : ', books.shape[0])
print('Jumlah data ratings : ', ratings.shape[0])
print('Jumlah data user : ', users.shape[0])

"""### Univariate Exploratory Data Analysis
Variabel-variabel pada book-recommendation-datasets adalah sebagai berikut :

*   books : data buku
*   ratings: data penilaian yang diberikan pengguna terhadap buku
*   user : data pengguna yang membaca buku

####  Books
eksplorasi data books yang merupakan daftar movie yang tersedia.
"""

books.head()

books.info()

"""####  Ratings
 eksplorasi data yang akan digunakan pada model yaitu data ratings.
"""

ratings.head()

ratings.info()

ratings.describe()

"""####  Users
 eksplorasi data data users yang merupakan pengguna sekaligus memberi rating
"""

users.head()

users.info()

"""### Data Preparation

#### Menggabungkan Books rating
menggabungkan beberapa data dengan fungsi marger berdasarkan pada ISBN, gabungkan seluruh data pada variabel books_rating
"""

book_ratings = ratings.merge(books,on='ISBN')
book_ratings.head(5)

"""Mencari jumlah rating berdasarkan Book-Title dan mengedit nama colum menjadi Rating Count"""

Rating_count = book_ratings.groupby('Book-Title').count()['Book-Rating'].reset_index()
Rating_count.rename(columns={'Book-Rating':'Rating Count'},inplace=True)
Rating_count.head(10)

"""Mencari rata rating berdasarkan Book-Title dan mengedit nama colum menjadi Avg Rating"""

AvgRating_count = book_ratings.groupby('Book-Title').mean()['Book-Rating'].reset_index()
AvgRating_count.rename(columns={'Book-Rating':'Avg Rating'},inplace=True)
AvgRating_count.head(10)

"""Menggabungkan data Rating count dan Avg count dengan menginisialisasi variable popular df"""

popular_df = Rating_count.merge(AvgRating_count,on='Book-Title')
popular_df

popular_df.describe()

"""Dari data diatas jumlah Rating count terkecil 1, karena kira akan membuat populer book, sehingga diambil data tersebut difilter bedasarkan count rating"""

popular_df = popular_df[popular_df['Rating Count']>=250]
popular_df.head(10)

"""Dari table diatas,

#### Missing value users
"""

users.isna().sum()

"""Dari table diatas colum Age ditable users memiliki missing value yang sangat banyak, sehingga column Age dihapus"""

users.drop('Age',axis=1,inplace=True)
users.head()

"""#### Missing value books"""

books.isna().sum()

"""Dari table diatas sedikit row yang memiliki value null, sehingga row tersebut dihapus"""

books.dropna(inplace=True)
books.isna().sum()

"""#### Missing value ratings"""

ratings.isna().sum()

"""#### Menggabungkan Books rating
menggabungkan beberapa data dengan fungsi marger berdasarkan pada ISBN, gabungkan seluruh data pada variabel books_rating
"""

book_ratings = ratings.merge(books,on='ISBN')
book_ratings.head(5)

"""Jumlah row pada data book ratings"""

book_ratings.shape

"""#### Filtering Book Ratings

Memfilter Book Rating yang memiliki jumlah rating > 200 mengelompokkan berdasarkan User-ID
"""

x = book_ratings.groupby('User-ID').count()['Book-Rating']>200
exp_users = x[x].index
exp_users

filtered_rating_users = book_ratings[book_ratings['User-ID'].isin(exp_users)]
filtered_rating_users

"""Memfilter Book Rating yang memiliki jumlah rating > 50 mengelompokkan berdasarkan Book-Title"""

y = filtered_rating_users.groupby('Book-Title').count()['Book-Rating']>50
famous_books = y[y].index

final_ratings = filtered_rating_users[filtered_rating_users['Book-Title'].isin(famous_books)]
final_ratings

"""### Modeling and Result
Proses modeling yang saya lakukan pada data ini adalah dengan membuat algoritma machine learning, yaitu content based filtering dan collabrative filtering. untuk algoritma content based filtering saya buat dengan apa yang disukai pengguna pada masa lalu, sedangkan untuk content based filtering, saya buat dengan memanfaatkan tingkat rating dari buku tersebut.

#### Model Development dengan Content Based Filtering
"""

final_df = final_ratings.pivot_table(index='Book-Title',columns='User-ID',values='Book-Rating')
final_df.fillna(0,inplace=True)
final_df

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

similarity_scores = cosine_similarity(final_df)
similarity_scores

def recommend(book):
    book_index = np.where(final_df.index == book)[0][0]
    distances = similarity_scores[book_index]
    book_list = sorted(list(enumerate(distances)),reverse=True,key=lambda x:x[1])[1:6]
    
    for i in book_list:
        print(final_df.index[i[0]])

recommend('1st to Die: A Novel')

recommend('Roses Are Red (Alex Cross Novels)')

"""Dari Hasil rekomendasi diatas, hasil rekomendasi buku 1st to Die: A Novel dan jika salah satu hasil tersbut dimasukkan ke rekomendasi dari 5 hasil rekomendasi terdapat 3 rekomendasi sama. Artinya, precision sistem kita sebesar 3/5 atau 60%

#### Model Development dengan Collaborative Filtering
"""

import pandas as pd
import numpy as np 
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

import tensorflow as tf
from tensorflow import keras

from tqdm.auto import trange

df = ratings#['Rating Count']>=250
df

# Mengubah User-ID menjadi list tanpa nilai yang sama
user_ids = df['User-ID'].unique().tolist()
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}

# Mengubah ISBN menjadi list tanpa nilai yang sama
isbn_ids = df['ISBN'].unique().tolist()
isbn_to_isbn_encoded = {x: i for i, x in enumerate(isbn_ids)}
isbn_encoded_to_isbn = {i: x for i, x in enumerate(isbn_to_isbn_encoded)}

"""Menambahkan column user dan book, berisi nilai integer"""

df['user'] = df['User-ID'].map(user_to_user_encoded)
df['book'] = df['ISBN'].map(isbn_to_isbn_encoded)

df

"""Mengecek jumlah pengguna dan jumlah buku, serta mengubah tipe data rating menjadi float

"""

num_users = len(user_to_user_encoded)
print(num_users)
 
num_isbn = len(isbn_encoded_to_isbn)
print(num_isbn)
 
df['Book-Rating'] = df['Book-Rating'].values.astype(np.float32)
 
min_rating = min(df['Book-Rating'])
 
max_rating = max(df['Book-Rating'])
 
print('Number of User: {}, Number of isbn: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_isbn, min_rating, max_rating
))

"""Mengacak dataset sebelum dijadikan data tran dan test"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

"""Membagi dataset train 70% dan latih 30%"""

# Membuat variabel x untuk mencocokkan data Book-Title
x = df[['user', 'book']].values
 
# Membuat variabel y untuk membuat ratings dari hasil 
y = df['Book-Rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
# Membagi menjadi 70% data train dan 20% data validasi
train_indices = int(0.7 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""##### Model Development

Model yang akan kita pakai dalam sistem rekomendasi berbasis pendapat pengguna adalah RecommenderNet
"""

class RecommenderNet(tf.keras.Model):
 
  # Insialisasi fungsi
  def __init__(self, num_users, num_isbn, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_isbn = num_isbn
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.movie_embedding = layers.Embedding( # layer embeddings movies
        num_isbn,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_isbn, 1) # layer embedding movies bias
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    movie_vector = self.movie_embedding(inputs[:, 1]) # memanggil layer embedding 3
    movie_bias = self.movie_bias(inputs[:, 1]) # memanggil layer embedding 4
 
    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2) 
 
    x = dot_user_movie + user_bias + movie_bias
    
    return tf.nn.sigmoid(x) # activation sigmoid

"""Selanjutnya kita melakukan proses compile pada model dengan binary crossentropy sebagai loss function, adam sebagai optimizer, dan RMSE sebagai metrik dari model


"""

model = RecommenderNet(num_users, num_isbn, 50) # inisialisasi model
 
# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Selanjutnya kita akan melatih model dengan batch_size 256 dan 20 epochs


"""

# Memulai training
 
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 64,
    epochs = 10,
    validation_data = (x_val, y_val)
)

"""##### Visualisasi Metrik

Berikut adalah hasil latihan dari data yang ada, evaluasi metrik yang digunakan adalah RMSE
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""##### Rekomendasi Test

"""

book_dataset = books
rating_dataset = df

user_id = rating_dataset['User-ID'].sample(1).iloc[0]
books_have_been_read_by_user = rating_dataset[rating_dataset['User-ID'] == user_id]
 
books_have_not_been_read_by_user = book_dataset[book_dataset['ISBN'].isin(books_have_been_read_by_user.ISBN.values)]['ISBN'] 
books_have_not_been_read_by_user = list(
    set(books_have_not_been_read_by_user)
    .intersection(set(isbn_to_isbn_encoded.keys()))
)
 
books_have_not_been_read_by_user = [[isbn_to_isbn_encoded.get(x)] for x in books_have_not_been_read_by_user]
user_encoder = user_to_user_encoded.get(user_id)
user_book_array = np.hstack(
    ([[user_encoder]] * len(books_have_not_been_read_by_user), books_have_not_been_read_by_user)
)

ratings = model.predict(user_book_array).flatten()
 
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_book_ids = [
    isbn_encoded_to_isbn.get(books_have_not_been_read_by_user[x][0]) for x in top_ratings_indices
]
 
top_books_recommended = (
    books_have_been_read_by_user.sort_values(
        by = 'Book-Rating',
        ascending=False
    )
    .head(5)
    .ISBN.values
)
 
books_row = book_dataset[book_dataset['ISBN'].isin(top_books_recommended)]
for row in books_row.itertuples():
    print(row[2], ':', row[3])
 
print('----' * 8)
print('Top 10 Book Recommendation for user: {}'.format(user_id))
print('----' * 8)
 
recommended_books = book_dataset[book_dataset['ISBN'].isin(recommended_book_ids)]
for row in recommended_books.itertuples():
    print(row[2], ':', row[3])

"""Berikut adalah sistem rekomendasi dari content dan collaborative based system. Keduanya unik dan memiliki kelebihan dan kekurangannya masing - masing."""